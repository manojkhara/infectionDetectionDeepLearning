{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manojkhara/infectionDetectionDeepLearning/blob/main/VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_Nv2IDm1v65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "b5643d96-6f0a-44e3-c24a-f733b502f358"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Module\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision.models as models\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary                                                \n",
        "from tensorflow import summary\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg \n",
        "from PIL import Image \n",
        "import cv2 as cv\n",
        "import csv\n",
        "import os\n",
        "from tqdm import tqdm_notebook                                                  \n",
        "import time\n",
        "import datetime\n",
        "import itertools\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyE0QIDaDWf_"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCg2x4O9ERU6"
      },
      "source": [
        "cd /content/drive/My Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgPYhznjE1WN"
      },
      "source": [
        "Train_set_path      = \"Pre-processed-images/feature-extracted-data/train\"\n",
        "Test_set_path       = \"Pre-processed-images/feature-extracted-data/test\"\n",
        "Train_values        = \"New_ODIR-5K_Training_Annotations(Updated)_V2.xlsx\"\n",
        "Validate_values     = \"New_ODIR-5K_Validation_Annotations(Updated)_V2.xlsx\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwjeNPQbHu5c"
      },
      "source": [
        "class ODIR_train():\n",
        "\n",
        "    def __init__(self, xlsx_file, root_dir1, transform=None): \n",
        "        self.read = pd.read_excel(xlsx_file)\n",
        "        self.root_dir1 = root_dir1\n",
        "        self.transform = transform\n",
        "   \n",
        "    def __len__(self):\n",
        "        return len(self.read)\n",
        "\n",
        "    def name(self,idx):\n",
        "      img_name_train = self.read.iloc[idx,3]\n",
        "      return(img_name_train)\n",
        "    \n",
        "    def condition_left(self,idx):\n",
        "      img_condition_train_left = self.read.iloc[idx,5]\n",
        "      return(img_condition_train_left)\n",
        "\n",
        "    def condition_right(self,idx):\n",
        "      img_condition_train_right = self.read.iloc[idx,6]\n",
        "      return(img_condition_train_right) \n",
        "\n",
        "    def __getitem__(self, idx):                              \n",
        "        img_path_train_left = os.path.join(self.root_dir1,self.read.iloc[idx,3])  \n",
        "        sample_train_left   = cv.imread(img_path_train_left)\n",
        "        img_path_train_right = os.path.join(self.root_dir1, self.read.iloc[idx, 4])\n",
        "        sample_train_right   = cv.imread(img_path_train_right)\n",
        "        img_path_label  = self.read.iloc[idx, 7:15]                              \n",
        "        img_path_label = img_path_label.astype(\"float\")\n",
        "        sample_label = np.asarray(img_path_label)\n",
        "        if self.transform:\n",
        "            sample_train_left = self.transform(sample_train_left)\n",
        "            sample_train_right = self.transform(sample_train_right)\n",
        "        return (sample_train_left,sample_train_right, sample_label)\n",
        "\n",
        "class ODIR_validation():\n",
        "\n",
        "    def __init__(self, xlsx_file, root_dir1,  transform=None): \n",
        "        self.read = pd.read_excel(xlsx_file)\n",
        "        self.root_dir1 = root_dir1\n",
        "        self.transform = transform\n",
        "   \n",
        "    def __len__(self):\n",
        "        return len(self.read)\n",
        "\n",
        "    def name(self,idx):\n",
        "      img_name_val = self.read.iloc[idx,3]\n",
        "      return(img_name_val)\n",
        "    \n",
        "    def condition_left(self,idx):\n",
        "      img_condition_val_left = self.read.iloc[idx,5]\n",
        "      return(img_condition_val_left)\n",
        "\n",
        "    def condition_right(self,idx):\n",
        "      img_condition_val_right = self.read.iloc[idx,6]\n",
        "      return(img_condition_val_right) \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path_val_left = os.path.join(self.root_dir1, self.read.iloc[idx, 3])\n",
        "        sample_val_left   = cv.imread(img_path_val_left)\n",
        "        img_path_val_right = os.path.join(self.root_dir1, self.read.iloc[idx, 4])\n",
        "        sample_val_right   = cv.imread(img_path_val_right)\n",
        "        img_path_label  = self.read.iloc[idx, 7:15]\n",
        "        img_path_label = img_path_label.astype(\"float\")\n",
        "        sample_label = np.asarray(img_path_label)\n",
        "        if self.transform:\n",
        "            sample_val_left = self.transform(sample_val_left)\n",
        "            sample_val_right = self.transform(sample_val_right)\n",
        "        return(sample_val_left,sample_val_right,sample_label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAK-0t3SOOXe"
      },
      "source": [
        "batch_size_train = 32\n",
        "batch_size_val = 32\n",
        "num_epochs =  9\n",
        "learning_rate = 0.005\n",
        "img_width = 224\n",
        "img_height = 224\n",
        "n_class = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GSJmRa7GQ3Q"
      },
      "source": [
        "composed_transform = transforms.Compose([transforms.ToPILImage(),transforms.Resize((299,299)),transforms.ToTensor()])\n",
        "traindata = ODIR_train( xlsx_file = Train_values,  root_dir1 = Train_set_path,  transform = composed_transform)\n",
        "trainloader = DataLoader(traindata, batch_size = batch_size_train, shuffle= False ,num_workers=0)\n",
        "validatedata = ODIR_validation( xlsx_file = Validate_values,  root_dir1 = Train_set_path,  transform = composed_transform)\n",
        "validateloader = DataLoader(validatedata, batch_size = batch_size_val, shuffle= False ,num_workers=0)\n",
        "l = len(traindata)\n",
        "for idx in range (l):\n",
        "    img = traindata[idx][0]\n",
        "    label = traindata[idx][1]\n",
        "    condition = traindata.condition_left(idx)\n",
        "    img = img.permute(2,1,0)\n",
        "    if idx ==2:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18H0OghUfq6D"
      },
      "source": [
        "model_conv = models.vgg11_bn(pretrained=False)\n",
        "for i, param in model_conv.named_parameters():\n",
        "  param.requires_grad = True\n",
        "num_ftrs = model_conv.classifier[6].in_features\n",
        "model_conv.classifier[6]= nn.Linear(num_ftrs, n_class)                      \n",
        "model_conv.cuda()\n",
        "criterion = nn.BCEWithLogitsLoss().cuda()                                      \n",
        "optimizer = torch.optim.SGD(model_conv.parameters(), lr=learning_rate, momentum = 0.5, weight_decay = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeKOqobzIwA7"
      },
      "source": [
        "def metrics(tar,out):\n",
        "    f = 0\n",
        "    r = 0\n",
        "    k = 0\n",
        "    a = 0\n",
        "    for i, c in enumerate(zip(out, tar)):\n",
        "        c[0][c[0] > 0.5] = 1                 \n",
        "        c[0][c[0] < 0.5] = 0\n",
        "        out = list(c[0])\n",
        "        tar = list(c[1])\n",
        "        f = f + f1_score(tar, out,average = 'weighted' )\n",
        "        r = r + roc_auc_score(tar, out )\n",
        "        k = k + cohen_kappa_score(tar, out )\n",
        "        a = a + accuracy_score(tar, out)\n",
        "    f = f / (i + 1)\n",
        "    r = r / (i + 1)\n",
        "    k = k / (i + 1)\n",
        "    a = a / (i + 1)\n",
        "    return(f,k,r,a)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh038MFDpQN4"
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VabPxEldQx8s"
      },
      "source": [
        "training_values = []\n",
        "validation_values = []\n",
        "accuracy_train_values =[]\n",
        "accuracy_val_values =[]\n",
        "for epoch in tqdm_notebook(range(num_epochs)):\n",
        "    print (epoch)    \n",
        "    epoch_loss = 0\n",
        "    f1_add = 0\n",
        "    accuracy_add = 0\n",
        "    k_add = 0\n",
        "    auc_add = 0\n",
        "    final_score = 0\n",
        "    for k,train_img in enumerate(trainloader):\n",
        "        print (type(train_img))\n",
        "        inputs_left,inputs_right,labels = train_img\n",
        "        final = torch.cat((inputs_left,inputs_right),2)\n",
        "        final = F.interpolate(final,224)\n",
        "        final = final.unsqueeze_(0)        \n",
        "        final = final.reshape(batch_size_train,3,img_width,img_height)\n",
        "        model_conv.train(mode=True)            \n",
        "        optimizer.zero_grad()                  \n",
        "        final = final.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = model_conv(final)                                  \n",
        "        loss = criterion(outputs, labels.float())                   \n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()                                              \n",
        "        optimizer.step()                                             \n",
        "        labels = labels.cpu().detach().numpy()\n",
        "        outputs = outputs.cpu().detach().numpy()\n",
        "        f1score_, k_score_, auc_score_,accuracy_score_ = metrics(labels, outputs)\n",
        "        f1_add    += f1score_\n",
        "        k_add     += k_score_\n",
        "        auc_add   += auc_score_\n",
        "        accuracy_add += accuracy_score_\n",
        "        final      = (f1score_ + k_score_ + auc_score_)/3\n",
        "        final_score += final        \n",
        "        if k == 30:         \n",
        "          break\n",
        "    if (epoch % 1 == 0):\n",
        "        print('[Training] Epoch [{}/{}] | Loss: {:.4f} | f1_score:{:.4f} | accuracy :{:4f} | kappa_score:{:4f} | auc_score:{:4f} | final_score:{:4f}'\n",
        "              .format(epoch+1, num_epochs, (epoch_loss/(k+1)), (f1_add/(k+1)),(accuracy_add/(k+1)),  \n",
        "              (k_add/(k+1)),(auc_add/(k+1)),final_score/(k+1) ))\n",
        "        training_values.append(epoch_loss/(k+1))\n",
        "        accuracy_train_values.append((accuracy_add/(k+1)))\n",
        "    epoch_loss_val = 0\n",
        "    f1_add_val = 0\n",
        "    accuracy_add_val = 0\n",
        "    k_add_val = 0\n",
        "    auc_add_val = 0\n",
        "    final_score_val = 0\n",
        "    for z,val_img in enumerate(validateloader):\n",
        "        inputs_left,inputs_right,labels = val_img\n",
        "        final = torch.cat((inputs_left,inputs_right),2)\n",
        "        final = F.interpolate(final,224)\n",
        "        final = final.unsqueeze_(0)\n",
        "        final = final.reshape(batch_size_train,3,img_width,img_height)\n",
        "        optimizer.zero_grad()                                         \n",
        "        with torch.no_grad(): \n",
        "            final = final.cuda()\n",
        "            labels = labels.cuda()\n",
        "            model_conv.eval()\n",
        "            outputs = model_conv(final)\n",
        "            loss = criterion(outputs, labels.float())\n",
        "            epoch_loss_val += loss.item()\n",
        "        labels = labels.cpu().detach().numpy()\n",
        "        outputs = outputs.cpu().detach().numpy()\n",
        "        f1score_, k_score_, roc_score_, accuracy_score_ = metrics(labels, outputs)\n",
        "        f1_add_val    += f1score_\n",
        "        k_add_val     += k_score_\n",
        "        auc_add_val   += roc_score_\n",
        "        accuracy_add_val += accuracy_score_\n",
        "        final      = (f1score_ + k_score_ + auc_score_)/3\n",
        "        final_score_val += final\n",
        "        if z == 6:              \n",
        "          break\n",
        "    print('[Validation][Epoch [{}/{}]  Loss: {:.4f} | f1_score:{:.4f} | accuracy_score:{:4f} | kappa_score:{:4f} | auc_score:{:4f} | final_score:{:4f}, '\n",
        "            .format(epoch+1, num_epochs, (epoch_loss_val/(z+1)), (f1_add_val/(z+1)), (accuracy_add_val/(z+1)), \n",
        "            (k_add_val/(z+1)),(auc_add_val/(z+1)),final_score_val/(z+1) ))\n",
        "    print('--------------------------------------------------------------------------------------------------------------------------------------------------')\n",
        "    validation_values.append(epoch_loss_val/(z+1))\n",
        "    accuracy_val_values.append((accuracy_add_val/(z+1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgTSpYLfiUnC"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from google.colab import files\n",
        "plt.figure()\n",
        "plt.plot(np.arange(num_epochs),training_values,'r--')\n",
        "plt.plot(np.arange(num_epochs),validation_values,'b')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()\n",
        "plt.savefig('vgg_loss_graph.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4RxCwUZeExY"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from google.colab import files\n",
        "plt.figure()\n",
        "plt.plot(np.arange(num_epochs),accuracy_train_values,'r--')\n",
        "plt.plot(np.arange(num_epochs),accuracy_val_values,'b')\n",
        "plt.ylabel('accuracy score')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()\n",
        "plt.savefig('vgg_f1score_graph.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81-lYAgvGt56"
      },
      "source": [
        "torch.save(model_conv.state_dict(), 'vgg_9epoch_nonpretrained_0001lr_BCE_SGD_concatenated_batch32_momentum05.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}